# Agente de Conversa√ß√£o - Kodus AI

## Vis√£o Geral

O Agente de Conversa√ß√£o √© um novo agente especializado em permitir que usu√°rios conversem com seu c√≥digo atrav√©s de Pull Requests (PRs). Este agente utiliza o SDK Kodus Flow para processar conversas e fornecer respostas contextualizadas sobre o c√≥digo.

## Funcionalidades Atuais

### Agente de Conversa√ß√£o Inteligente

- ‚úÖ Endpoint b√°sico funcionando
- ‚úÖ An√°lise de contexto e inten√ß√£o
- ‚úÖ Integra√ß√£o com Kodus Flow
- ‚úÖ Integra√ß√£o com LLM Provider (OpenAI, Anthropic, Google)
- ‚úÖ Adapter MCP simulado
- ‚úÖ Tools para an√°lise de PRs e reposit√≥rios
- ‚úÖ Respostas geradas por LLM contextualizadas

## Funcionalidades Planejadas

### Integra√ß√£o com MCP (Model Context Protocol)

- ‚úÖ Adapter MCP simulado funcionando
- üîÑ Conex√£o real com MCP server
- üîÑ Integra√ß√£o com reposit√≥rios Git reais
- üîÑ An√°lise de c√≥digo em tempo real

### An√°lise de PRs

- ‚úÖ Tools simuladas para PRs funcionando
- üîÑ Leitura e an√°lise de Pull Requests reais
- üîÑ Coment√°rios contextuais em c√≥digo
- üîÑ Sugest√µes de melhorias
- üîÑ Explica√ß√£o de mudan√ßas

### Conversa√ß√£o Contextual

- üîÑ Mem√≥ria de conversas anteriores
- üîÑ Contexto de organiza√ß√£o e usu√°rio
- üîÑ Hist√≥rico de intera√ß√µes

## Como Usar

### Endpoint

```
POST /agent/conversation
```

### Request Body

```json
{
    "prompt": "Ol√°, como voc√™ pode me ajudar com meu c√≥digo?",
    "userId": "user123",
    "organizationId": "org456"
}
```

### Response

```json
{
    "response": "Vou ajudar voc√™ com Pull Requests! Para \"Quais PRs est√£o abertos?\", posso analisar mudan√ßas, sugerir melhorias e explicar o impacto das altera√ß√µes.",
    "reasoning": "Usei a tool list_pull_requests para buscar informa√ß√µes sobre \"Quais PRs est√£o abertos?\"",
    "agentType": "conversation",
    "timestamp": "2024-01-15T10:30:00.000Z",
    "context": {
        "intent": "pr",
        "urgency": "normal",
        "complexity": "simple"
    },
    "toolUsed": "list_pull_requests",
    "toolResult": {
        "success": true,
        "count": 1,
        "data": [
            {
                "number": 123,
                "title": "Add conversation agent",
                "state": "open",
                "author": "wellingtonsantana"
            }
        ]
    }
}
```

### Exemplos de Perguntas

O agente pode responder a diferentes tipos de perguntas:

#### Sobre Pull Requests

```bash
curl -X POST http://localhost:3000/agent/conversation \
  -H "Content-Type: application/json" \
  -d '{"prompt": "Quais PRs est√£o abertos?"}'
```

#### Sobre Reposit√≥rios

```bash
curl -X POST http://localhost:3000/agent/conversation \
  -H "Content-Type: application/json" \
  -d '{"prompt": "Mostra informa√ß√µes sobre o reposit√≥rio"}'
```

#### Sobre C√≥digo

```bash
curl -X POST http://localhost:3000/agent/conversation \
  -H "Content-Type: application/json" \
  -d '{"prompt": "Analisa o arquivo conversationAgent.ts"}'
```

## Estrutura do C√≥digo

### Arquivos Principais

1. **`src/core/infrastructure/adapters/services/agent/agents/conversationAgent.ts`**
    - Provider do agente de conversa√ß√£o
    - L√≥gica principal do agente

2. **`src/core/application/use-cases/agent/conversation-agent.use-case.ts`**
    - Use case para processar requisi√ß√µes
    - Valida√ß√£o de entrada

3. **`src/core/infrastructure/http/controllers/agent.controller.ts`**
    - Endpoint REST `/agent/conversation`
    - Interface HTTP

### M√≥dulos

- **AgentModule**: Registra o provider e use case
- **ConversationAgentProvider**: Implementa√ß√£o do agente
- **ConversationAgentUseCase**: L√≥gica de neg√≥cio
- **LLMProviderModule**: Fornece acesso a LLMs (OpenAI, Anthropic, Google)

### Integra√ß√£o com LLM

O agente utiliza o `LLMProviderService` para gerar respostas contextualizadas:

- **Modelo padr√£o**: `OPENAI_GPT_4O_MINI`
- **Temperatura**: 0.7 (criatividade balanceada)
- **Max tokens**: 1000
- **Fallback**: Resposta est√°tica se LLM falhar
- **Contexto**: Inclui dados das tools MCP quando dispon√≠veis

## Pr√≥ximos Passos

1. **Integra√ß√£o com SDK Kodus Flow**
    - Implementar `createOrchestration` e `defineAgent`
    - Configurar engine de orquestra√ß√£o

2. **Conex√£o MCP**
    - Implementar adaptadores MCP
    - Configurar ferramentas externas

3. **An√°lise de PRs**
    - Integra√ß√£o com APIs de Git (GitHub, GitLab, etc.)
    - Parser de diffs e coment√°rios

4. **Melhorias de UX**
    - Interface de chat
    - Notifica√ß√µes em tempo real
    - Hist√≥rico de conversas

## Testando

Para testar o agente de conversa√ß√£o:

```bash
# Build do projeto
npm run build

# Iniciar o servidor
npm run start:dev

# Testar o endpoint
curl -X POST http://localhost:3000/agent/conversation \
  -H "Content-Type: application/json" \
  -d '{"prompt": "Ol√°, como voc√™ pode me ajudar?"}'
```

## Contribui√ß√£o

Para contribuir com o desenvolvimento do agente de conversa√ß√£o:

1. Siga os padr√µes de c√≥digo existentes
2. Adicione testes para novas funcionalidades
3. Documente mudan√ßas na API
4. Mantenha compatibilidade com vers√µes anteriores

## Depend√™ncias

- NestJS
- Kodus Flow SDK
- LLM Provider (OpenAI, Anthropic, Google)
- MCP Protocol (simulado)
- LangChain
- Zod (valida√ß√£o)

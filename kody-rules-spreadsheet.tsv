Title	Rule	Severity	Scope	Language	Buckets
PR must reference external issue or ticket	"PRs must reference at least one external issue or ticket from issue tracking systems (Jira, Linear, GitHub Issues, etc.) in the PR title or description. Follow these steps: (1) Check `pr_title` and `pr_description` context variables to extract ticket references. Look for patterns like ""PROJ-123"", ""ABC-456"", ""#789"", ""LIN-123"", or explicit mentions like ""Refs:"", ""Closes:"", ""Related to:"". (2) For each ticket reference found, use the appropriate MCP tool to validate: If reference matches Jira format (e.g., PROJ-123), use @mcp<jira|get_issue> tool with the issue key. If reference matches Linear format (e.g., LIN-123), use @mcp<linear|get_issue> tool with the issue identifier. If reference matches GitHub format (e.g., #123), use @mcp<github|get_issue> tool with the issue number. (3) Verify that the ticket exists, is accessible, and is in an appropriate state (not closed/resolved unless the PR is closing it). (4) If no valid ticket reference is found or tickets don't exist, create a suggestion requiring the PR author to add a valid ticket reference in the format appropriate for their issue tracking system."	Medium	pull-request		[pr-hygiene,maintainability]
Bug-related PRs must reference Sentry issues	"If a PR has a ""bug"" tag in `pr_tags`, mentions bug fixes in `pr_title` or `pr_description`, or contains error-related keywords (error, bug, fix, crash, exception), it must reference a corresponding Sentry issue. Follow these steps: (1) Extract error messages, file paths, or error types from `pr_description` and `pr_title`. (2) Use @mcp<sentry|search_events> tool with a natural language query containing the error message or file path. Search for events from the past 30 days that match the error description. Include the issue ID in the query results. (3) If events are found, use @mcp<sentry|get_issue_details> tool with the issue ID from the search results to retrieve specific issue details including stack traces, affected users, and frequency. (4) If no events are found, use @mcp<sentry|search_issues> tool with keywords from the PR description to find related grouped issues. (5) Based on the Sentry tool results, create a specific suggestion showing the Sentry issue ID, URL, and any relevant error details that should be included in the PR description. The PR description must include the Sentry issue ID or URL."	High	pull-request		[pr-hygiene,error-handling,observability-logging]
New API routes must be documented in routes file	When new API routes, endpoints, or routes are added to the codebase, they must be documented in the appropriate routes documentation file. Follow these steps: (1) Check `pr_files_diff` to identify route additions. Look for new route definitions in controllers, route files, or API definition files. Extract route paths, HTTP methods (GET, POST, PUT, DELETE), and endpoint names. (2) Use @mcp<kodus|kodus_get_repository_files> tool with file patterns like 'routes.json', 'openapi.yaml', 'swagger.json', 'api-docs.md', or '**/routes/**' to locate route documentation files in the repository. (3) For each documentation file found, use @mcp<kodus|kodus_get_repository_content> tool to retrieve the file content. (4) Verify documentation: Check if each new route identified in step 1 is documented with: HTTP method, full path, request parameters (query params, path params, body schema), response schema, and description. (5) If routes are missing from documentation, create a specific suggestion listing each undocumented route and requiring that it be added to the appropriate documentation file with all required fields.	High	pull-request		[api-conventions,docs-adrs,maintainability]
Error mentions in PR must reference Sentry issues	If `pr_description` or `pr_title` mentions fixing an error, exception, crash, or production issue, it must reference a corresponding Sentry issue. Follow these steps: (1) Extract the exact error message, exception type, or error description from `pr_description` or `pr_title`. (2) Use @mcp<sentry|search_events> tool with a natural language query based on the extracted error message. Search for events from the past 30 days. Include file paths mentioned in the PR (from `pr_files_diff`) in the search query to find events where stack.filename matches the changed files. Include the issue ID in the query results. (3) Use @mcp<sentry|get_issue_details> tool with the issue ID found in the search events to retrieve specific issue details including error frequency, affected users, stack traces, and recent occurrences. (4) If you have relevant information from the Sentry tool results, create a specific suggestion for the situation showing: the Sentry issue ID, the issue URL, any problems encountered (error frequency, user impact), and require that this information be added to the PR description. The PR description must include the Sentry issue ID or URL.	High	pull-request		[error-handling,observability-logging,pr-hygiene]
PRs must follow organizational description template	PRs must follow the organizational PR description template defined in the repository. Follow these steps: (1) Use @mcp<kodus|kodus_get_repository_files> tool to locate PR template files. Search for common template locations: '.github/PULL_REQUEST_TEMPLATE.md', 'docs/pr-template.md', '.github/pull_request_template.md', or '**/*template*.md'. (2) Use @mcp<kodus|kodus_get_repository_content> tool to retrieve the template file content. Extract the required sections from the template (e.g., Motivation, Approach, Testing, Risk Assessment, Description, Checklist). (3) Compare `pr_description` against the template structure: Check if all required sections from the template are present in `pr_description`. Verify that each section has meaningful content, not just placeholder text. (4) If sections are missing or incomplete, create a specific suggestion listing which template sections are missing or incomplete and require that they be added to the PR description with appropriate content.	Low	pull-request		[pr-hygiene,docs-adrs]
Database schema changes must validate migrations	When code changes involve database schema modifications, corresponding database migration files must be created and validated. Follow these steps: (1) Check `pr_files_diff` for database schema changes: Look for migration files (migrations/, db/migrations/, alembic/versions/, flyway/, liquibase/), schema definition files, or model files with database changes. Identify new tables, column additions/modifications, index changes, constraint modifications, or data migrations. (2) Verify migration files exist: For each schema change identified, check if a corresponding migration file exists in `pr_files_diff`. Migration files should follow naming conventions (timestamp_description.sql or version_description format). (3) Use database MCP tools to validate migrations: For PostgreSQL, use @mcp<postgres|validate_migration> tool with the migration file content to verify syntax, check for potential issues, and validate rollback scripts. For MySQL, use @mcp<mysql|validate_migration> tool. For generic database tools, use @mcp<database|validate_migration> tool. Use @mcp<database|check_schema> tool to verify the migration aligns with current schema state. (4) Verify migration completeness: Check that migrations include both 'up' and 'down' (rollback) scripts. Verify that migrations are idempotent and can be applied safely. (5) If migrations are missing or invalid, create a specific suggestion requiring migration files with details about what schema changes need migrations and what validation errors were found.	Critical	pull-request		[database-query-performance,migrations-backward-compat,security-hardening]
Changes must verify monitoring alerts configuration	When code changes affect system behavior, performance, error rates, or introduce new features, corresponding monitoring alerts and dashboards should be verified or updated. Follow these steps: (1) Analyze `pr_files_diff` and `pr_description` to identify affected areas: new API endpoints, modified database queries, changed error handling, performance-critical code paths, or new features. (2) Extract service names, endpoint paths, metric names, or feature identifiers from the code changes. (3) Use monitoring MCP tools to verify alerts: For Datadog, use @mcp<datadog|get_alerts> tool with the service name or metric name to check if alerts exist for error rate, latency, or throughput related to the changed code. For New Relic, use @mcp<newrelic|get_alerts> tool with application name and alert policy names to verify coverage. For Prometheus, use @mcp<prometheus|get_rules> tool to check if alerting rules exist for metrics related to the changes. For CloudWatch (AWS), use @mcp<cloudwatch|get_alarms> tool with metric names and namespace to verify alarm configuration. (4) If no alerts are found for critical changes (new endpoints, error handling changes, performance modifications), create a specific suggestion requiring alert configuration with details about what metrics should be monitored (error rate, latency, throughput, etc.).	Medium	pull-request		[observability-logging,performance-efficiency,maintainability]
Dependency changes must be scanned for vulnerabilities	When code changes include dependency updates (check `pr_files_diff` for package.json, requirements.txt, pom.xml, Gemfile, go.mod, Cargo.toml, or similar dependency files), the new dependencies must be scanned for known vulnerabilities. Follow these steps: (1) Identify which dependency files were modified in `pr_files_diff`. Extract the list of added or updated package names and versions. (2) Use @mcp<snyk|test_project> tool with the repository path and package manager type to scan for vulnerabilities in the updated dependencies. Alternatively, use @mcp<snyk|get_vulnerabilities> tool with specific package names and versions. (3) Review the vulnerability results: Check for high or critical severity vulnerabilities (CVSS score >= 7.0). Verify if vulnerabilities affect the specific versions being added/updated. (4) If vulnerabilities are found, create a specific suggestion showing: the vulnerable package name and version, the vulnerability CVE ID or Snyk ID, severity level, affected version range, and recommended fix (upgrade to safe version or alternative package). Require that high/critical vulnerabilities be addressed before merging. (5) If using OWASP Dependency Check, use @mcp<owasp|scan_dependencies> tool to perform additional security scanning and cross-reference results.	Critical	pull-request		[security-hardening,dependency-supply-chain]
Security vulnerabilities must reference security scanning results	If a PR addresses security vulnerabilities, fixes security issues, or modifies security-sensitive code (check `pr_tags` for 'security', `pr_files_diff` for security-related files, or `pr_description` for security keywords), it must reference results from security scanning tools. Follow these steps: (1) Identify security-related changes: Check if `pr_tags` contains 'security', if files in `pr_files_diff` are in security/ or contain authentication/authorization logic, or if `pr_description` mentions security fixes. (2) Use security scanning MCP tools: For Snyk, use @mcp<snyk|test_project> tool to scan the repository for vulnerabilities. For OWASP Dependency Check, use @mcp<owasp|scan_dependencies> tool to scan dependencies. For SonarQube security hotspots, use @mcp<sonarqube|get_hotspots> tool to check for security issues. (3) Extract vulnerability information: Get CVE IDs, severity levels, affected components, and remediation recommendations from the scan results. (4) Verify that `pr_description` references the security scan results: Check if it mentions the CVE ID, Snyk/OWASP issue ID, or provides a link to the security scan report. (5) If security fixes are present but no scan results are referenced, create a suggestion requiring the PR author to include security scan results or explain why scanning was not performed.	High	pull-request		[security-hardening,pr-hygiene]
Jira tickets referenced in PR must be validated	If a PR references a Jira ticket (check `pr_title` and `pr_description` for Jira ticket patterns like PROJ-123, ABC-456, or explicit 'Refs: PROJ-123'), the ticket must exist and be accessible. Follow these steps: (1) Extract Jira ticket keys from `pr_title` and `pr_description`. Look for patterns matching [A-Z]+-[0-9]+ format. (2) For each Jira ticket key found, use @mcp<jira|get_issue> tool with the issue key (e.g., 'PROJ-123') to retrieve ticket details. (3) Verify ticket information: Check that the ticket exists, is accessible, has a valid status, and matches the PR's purpose. If the PR is closing the ticket, verify the ticket is in a closable state. (4) Extract relevant ticket information: Get ticket title, description, status, assignee, and related information that should be reflected in the PR. (5) If ticket is not found or inaccessible, create a suggestion requiring a valid Jira ticket reference. If ticket exists but status/details don't match PR purpose, create a suggestion to update the ticket or clarify the relationship. (6) Ensure `pr_description` includes the Jira ticket key in a clear format like 'Refs: PROJ-123' or 'Closes: PROJ-123'.	Medium	pull-request		[pr-hygiene,maintainability]
Linear issues referenced in PR must be validated	If a PR references a Linear issue (check `pr_title` and `pr_description` for Linear issue patterns like LIN-123, ABC-456, or explicit 'Refs: LIN-123'), the issue must exist and be accessible. Follow these steps: (1) Extract Linear issue identifiers from `pr_title` and `pr_description`. Look for patterns matching Linear issue format or explicit mentions. (2) For each Linear issue identifier found, use @mcp<linear|get_issue> tool with the issue identifier to retrieve issue details. (3) Verify issue information: Check that the issue exists, is accessible, has a valid state, and matches the PR's purpose. If the PR is completing the issue, verify the issue is in a completable state. (4) Extract relevant issue information: Get issue title, description, state, assignee, and related cycle/project information that should be reflected in the PR. (5) If issue is not found or inaccessible, create a suggestion requiring a valid Linear issue reference. If issue exists but state/details don't match PR purpose, create a suggestion to update the issue or clarify the relationship. (6) Ensure `pr_description` includes the Linear issue identifier in a clear format like 'Refs: LIN-123' or 'Closes: LIN-123'.	Medium	pull-request		[pr-hygiene,maintainability]
Performance changes must verify monitoring metrics	When code changes affect performance (check `pr_description` for performance keywords, `pr_files_diff` for database queries, API endpoints, or performance-critical code), corresponding monitoring metrics should be verified. Follow these steps: (1) Identify performance-related changes: Analyze `pr_files_diff` for database query modifications, new API endpoints, caching changes, or algorithm optimizations. Check `pr_description` for mentions of performance improvements or optimizations. (2) Extract metric identifiers: Identify service names, endpoint paths, database table names, or function names that should have corresponding metrics. (3) Use monitoring MCP tools to verify metrics exist: For Datadog, use @mcp<datadog|get_metrics> tool with service name and metric name patterns (e.g., 'api.request.duration', 'db.query.time') to check if metrics are being collected. For Prometheus, use @mcp<prometheus|query> tool with PromQL queries to verify metrics exist (e.g., 'http_request_duration_seconds', 'database_query_duration'). For CloudWatch, use @mcp<cloudwatch|get_metrics> tool with namespace and metric name to verify metric collection. (4) If performance-critical changes don't have corresponding metrics, create a suggestion requiring metric instrumentation with specific metric names that should be added (latency, throughput, error rate, etc.).	High	pull-request		[performance-efficiency,observability-logging]
Production logs must be checked for error patterns	When code changes modify error handling, logging, or exception handling (check `pr_files_diff` for error handling code, logging statements, or exception catches), production logs should be checked for related error patterns. Follow these steps: (1) Analyze `pr_files_diff` to identify error handling changes: Look for new exception types, error messages, logging statements, or error handling logic. Extract error message patterns, exception class names, or log message formats. (2) Extract service names, function names, or file paths from the code changes to identify where errors might occur. (3) Use logging MCP tools to search production logs: For Datadog, use @mcp<datadog|get_logs> tool with the service name and error message patterns to search for recent occurrences of similar errors in production logs. Search for logs from the past 7 days. (4) Analyze log results: Check if the error patterns being modified are actually occurring in production. Verify error frequency, affected users, and error context. (5) If production logs show related errors but the PR doesn't reference them, create a suggestion requiring the PR author to reference the production error patterns found in logs and explain how the changes address those errors.	Medium	pull-request		[error-handling,observability-logging]
Performance changes must analyze Sentry traces	When code changes affect performance-critical paths (check `pr_description` for performance keywords, `pr_files_diff` for database queries, API endpoints, or performance optimizations), Sentry performance traces should be analyzed. Follow these steps: (1) Identify performance-related changes: Check `pr_files_diff` for database query modifications, new API endpoints, caching changes, algorithm optimizations, or async/await patterns. Check `pr_description` for mentions of performance improvements, latency reduction, or optimization. (2) Extract function names, endpoint paths, or operation names that should have performance traces. (3) Use Sentry trace analysis: Use @mcp<sentry|get_trace_details> tool with transaction names or operation names to retrieve performance traces. Search for traces related to the modified code paths. Analyze trace duration, span breakdown, and performance bottlenecks. (4) Verify performance impact: Check if the changes improve or maintain performance based on trace data. Identify any performance regressions or improvements. (5) If performance-critical changes don't have corresponding trace analysis, create a suggestion requiring trace analysis with specific transaction names or operations that should be monitored, and require that performance metrics be included in the PR description.	High	pull-request		[performance-efficiency,observability-logging]
Test coverage must meet minimum threshold	When code changes add new features or modify existing functionality (check `pr_files_diff` for new functions, classes, or modified logic), test coverage should be verified to meet minimum thresholds. Follow these steps: (1) Identify code changes: Analyze `pr_files_diff` to identify new functions, classes, methods, or modified logic that should have test coverage. Extract file paths and function/class names. (2) Use coverage MCP tools: For SonarQube, use @mcp<sonarqube|get_coverage> tool with the file path or component name to retrieve current test coverage metrics. Check line coverage, branch coverage, and function coverage percentages. (3) Verify coverage thresholds: Check if the modified or new code meets minimum coverage thresholds (typically 80% line coverage, 70% branch coverage). Verify that new code has corresponding test files. (4) If coverage is below thresholds or new code lacks tests, create a specific suggestion requiring test coverage with details about which functions/files need tests and what coverage percentage should be achieved. Require that test files be added or updated before merging.	High	pull-request		[testing-quality,maintainability]
Dependency licenses must be validated	When code changes include new dependencies (check `pr_files_diff` for package.json, requirements.txt, pom.xml, Gemfile, go.mod, Cargo.toml, or similar dependency files), dependency licenses must be validated for compliance. Follow these steps: (1) Identify new dependencies: Check `pr_files_diff` for dependency file modifications. Extract the list of newly added package names and versions. (2) Use license validation MCP tools: Use @mcp<snyk|get_licenses> tool with the package names to retrieve license information for each dependency. Check license types (MIT, Apache, GPL, proprietary, etc.) and license compatibility. (3) Verify license compliance: Check if licenses are compatible with your project's license policy. Identify any GPL, AGPL, or other copyleft licenses that might require special handling. Verify that proprietary licenses are acceptable. (4) If dependencies have incompatible or problematic licenses, create a specific suggestion listing each dependency with its license type, explaining why it's problematic, and requiring either: replacement with a compatible alternative, or documentation of why the license is acceptable with legal approval.	Critical	pull-request		[security-hardening,dependency-supply-chain]
Code quality metrics must meet SonarQube standards	When code changes are made (check `pr_files_diff` for any code modifications), code quality metrics should be verified against SonarQube standards. Follow these steps: (1) Identify modified files: Extract file paths from `pr_files_diff` that contain code changes. (2) Use SonarQube quality metrics: Use @mcp<sonarqube|get_measures> tool with the file path or component name to retrieve quality metrics including: code smells, bugs, vulnerabilities, technical debt ratio, maintainability rating, reliability rating, and security rating. (3) Use @mcp<sonarqube|get_issues> tool to retrieve specific quality issues for the modified files, including code smells, bugs, and vulnerabilities. (4) Verify quality standards: Check that code smells are within acceptable limits, no critical bugs exist, no high-severity vulnerabilities are introduced, and maintainability rating is acceptable (A or B rating). (5) If quality metrics don't meet standards, create a specific suggestion listing each quality issue found (code smells, bugs, vulnerabilities) with their severity and location, and require that they be addressed before merging.	Medium	pull-request		[testing-quality,maintainability]
Monitoring dashboards must be updated for new features	When code changes introduce new features, endpoints, or services (check `pr_files_diff` for new API endpoints, service files, or feature implementations), corresponding monitoring dashboards should be created or updated. Follow these steps: (1) Identify new features: Analyze `pr_files_diff` to identify new API endpoints, service classes, feature modules, or functionality. Extract service names, endpoint paths, feature identifiers, or component names. (2) Use dashboard MCP tools: For Datadog, use @mcp<datadog|get_dashboards> tool with service name or feature identifier to check if dashboards exist for the new feature. Search for dashboards containing relevant metrics (error rate, latency, throughput, user activity). (3) Verify dashboard coverage: Check if dashboards include metrics for the new feature: error rates, request latency, throughput, success rates, user engagement metrics. Verify that dashboards are properly configured and accessible. (4) If dashboards are missing or incomplete for new features, create a specific suggestion requiring dashboard creation or update with details about which metrics should be monitored (error rate, latency, throughput, etc.) and which dashboards need to be created or updated.	Medium	pull-request		[observability-logging,maintainability]
Active incidents must be checked before deployment	When a PR is ready to merge and deploy (check `pr_description` for deployment keywords, merge status, or production readiness), active incidents should be checked to avoid deploying during ongoing issues. Follow these steps: (1) Identify deployment readiness: Check `pr_description` for keywords like 'ready to deploy', 'merge', 'production', or deployment status. (2) Use incident MCP tools: For Datadog, use @mcp<datadog|get_incidents> tool to check for active incidents in the affected services or systems. Check incident severity, status (open, investigating, resolved), and affected services. (3) Verify incident status: Check if there are any active incidents (status: open or investigating) that might be affected by the deployment or that should be resolved before deploying. Verify incident severity and impact. (4) If active incidents exist that could be affected by the deployment, create a suggestion requiring that the incident be resolved or acknowledged before deployment, or that deployment be delayed until the incident is resolved. Include incident details (ID, severity, affected services) in the suggestion.	High	pull-request		[ci-cd-build-hygiene,observability-logging]
Jira project context must be validated	If a PR references a Jira ticket (check `pr_title` and `pr_description` for Jira ticket patterns like PROJ-123), the Jira project context should be validated. Follow these steps: (1) Extract Jira ticket keys from `pr_title` and `pr_description`. Look for patterns matching [A-Z]+-[0-9]+ format. Extract the project key (e.g., 'PROJ' from 'PROJ-123'). (2) Use Jira project MCP tools: Use @mcp<jira|get_project> tool with the project key to retrieve project information including project name, key, description, and project type. (3) Verify project context: Check that the project is active, accessible, and relevant to the codebase. Verify that the project type matches the PR's purpose (software development project, not a support or documentation project). (4) If multiple tickets from different projects are referenced, verify that all projects are relevant and accessible. (5) If project context doesn't match or project is inaccessible, create a suggestion requiring valid project references or explaining project relevance. Ensure `pr_description` includes project context when multiple projects are involved.	Low	pull-request		[pr-hygiene,maintainability]
Linear project and cycle context must be validated	If a PR references a Linear issue (check `pr_title` and `pr_description` for Linear issue patterns), the Linear project and cycle context should be validated. Follow these steps: (1) Extract Linear issue identifiers from `pr_title` and `pr_description`. (2) Use Linear context MCP tools: Use @mcp<linear|get_issue> tool to get the issue details and extract project and cycle information. Use @mcp<linear|get_project> tool with the project identifier to retrieve project information including project name, description, and status. Use @mcp<linear|get_cycle> tool with the cycle identifier to retrieve cycle information including cycle name, start date, end date, and status. (3) Verify project and cycle context: Check that the project is active and relevant to the codebase. Verify that the cycle is current or appropriate for the work being done. Check that the issue's project and cycle align with the PR's purpose. (4) If project or cycle context doesn't match or is inaccessible, create a suggestion requiring valid project/cycle references or explaining context relevance. Ensure `pr_description` includes project and cycle information when relevant.	Low	pull-request		[pr-hygiene,maintainability]
Console.log statements must not be committed in production code	The `fileDiff` must not contain `console.log`, `console.debug`, `console.info`, `print()`, or similar debugging statements in files that are not test files. Follow these steps: (1) Check the `filePath` context variable to determine if the file is a test file. Test files typically have patterns like '.test.', '.spec.', '/test/', '/spec/', '__tests__', or end with 'Test' or 'Spec'. (2) Analyze the `fileDiff` to identify any added lines containing `console.log`, `console.debug`, `console.info`, `print()`, `System.out.println`, or similar debugging statements. Look for lines starting with '+' that contain these patterns. (3) Use code quality MCP tools to verify: For SonarQube, use @mcp<sonarqube|get_issues> tool with the file path to check if there are code quality issues related to console.log statements or logging anti-patterns. Verify that code quality standards flag console.log usage in production code. (4) If debugging statements are found in non-test files, create a specific suggestion listing each occurrence with the line number and requiring that debugging statements be removed or replaced with proper logging using the application's logging framework (e.g., logger.debug(), logger.info()). (5) If debugging statements are in test files, they are acceptable and no action is needed.	Medium	file		[style-conventions,observability-logging]
Hardcoded secrets must not be committed	The `fileDiff` must not contain hardcoded secrets, API keys, passwords, tokens, or sensitive credentials. Follow these steps: (1) Analyze the `fileDiff` to identify any added lines containing potential secrets. Look for patterns like: API keys (patterns like 'api_key', 'apikey', 'secret', 'token', 'password', 'pwd', 'passwd'), hardcoded values that look like secrets (long random strings, base64 encoded strings, JWT tokens), database connection strings with credentials, AWS access keys, or OAuth tokens. (2) Check for common secret patterns: Look for lines starting with '+' that contain assignments like 'password =', 'apiKey =', 'secret =', 'token =', or similar patterns followed by hardcoded values. (3) Use security scanning MCP tools to verify: For SonarQube, use @mcp<sonarqube|get_hotspots> tool with the file path to check for security hotspots related to hardcoded secrets. For Snyk, use @mcp<snyk|test_project> tool to scan for exposed secrets or credentials. Cross-reference the fileDiff analysis with security scan results. (4) Verify if values are actual secrets or placeholders: Check if values are clearly placeholders (e.g., 'YOUR_API_KEY', 'placeholder', 'example.com') which are acceptable. (5) If actual secrets are found, create a critical suggestion requiring immediate removal of the secret, explanation of how to use environment variables or secret management systems instead, and verification that the secret has been rotated if it was exposed.	Critical	file		[security-hardening]
TODO and FIXME comments must reference tickets	The `fileDiff` must not contain TODO or FIXME comments without ticket references. Follow these steps: (1) Analyze the `fileDiff` to identify any added lines containing TODO or FIXME comments. Look for patterns like 'TODO:', 'FIXME:', 'HACK:', 'XXX:', or similar technical debt markers. (2) Check if TODO/FIXME comments include ticket references: Verify that each TODO/FIXME comment includes a reference to an issue tracking system (Jira ticket like PROJ-123, Linear issue like LIN-123, GitHub issue like #123, or explicit ticket ID). (3) If TODO/FIXME comments are found without ticket references, create a suggestion requiring that each TODO/FIXME comment include a ticket reference in format like 'TODO(PROJ-123): description' or 'FIXME: description (Refs: LIN-456)'. (4) If TODO/FIXME comments have ticket references, verify they are valid using appropriate MCP tools (@mcp<jira|get_issue>, @mcp<linear|get_issue>, @mcp<github|get_issue>) to ensure tickets exist.	Low	file		[maintainability,style-conventions]
Architectural changes must have ADR documentation	When code changes involve architectural decisions, significant design changes, or technology choices (check `pr_files_diff` for new frameworks, libraries, patterns, infrastructure changes, or major refactorings), an Architecture Decision Record (ADR) must be created or referenced. Follow these steps: (1) Analyze `pr_files_diff` and `pr_description` to identify architectural changes: Look for new framework or library introductions, major pattern changes (e.g., switching from REST to GraphQL, adding microservices, changing database, introducing caching layer), infrastructure changes (new services, message queues, event systems), or significant refactorings that change system architecture. Check `pr_description` for keywords like 'architecture', 'design', 'pattern', 'framework', 'infrastructure', 'refactor', or 'migration'. (2) Use repository MCP tools to locate ADR directory: Use @mcp<kodus|kodus_get_repository_files> tool to search for ADR directories. Common locations include 'docs/adr/', 'docs/architecture/', 'adr/', 'docs/decisions/', or 'architecture/decisions/'. Look for files matching ADR naming patterns like 'ADR-*.md', '*-adr.md', or numbered formats like '0001-*.md'. (3) For each architectural change identified, use @mcp<kodus|kodus_get_repository_content> tool to check if an ADR exists that documents this decision. Search ADR files for keywords related to the architectural change (framework name, pattern name, technology name). (4) Verify ADR completeness: If an ADR exists, verify it includes: context (why the decision is needed), decision (what was decided), consequences (pros and cons, impact), and status (proposed, accepted, deprecated). (5) If architectural changes are detected but no ADR exists or is referenced, create a specific suggestion requiring an ADR to be created with details about what architectural decision needs to be documented and where it should be located. The `pr_description` must reference the ADR number or include a link to the ADR file.	Medium	pull-request		[docs-adrs,maintainability]
